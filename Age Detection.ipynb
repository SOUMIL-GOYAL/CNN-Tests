{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "import time\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "# Setting random seeds to reduce the amount of randomness in the neural net weights and results.\n",
    "# The results may still not be exactly reproducible.\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the installed version of TensorFlow.\n",
    "# The code in this notebook was written using TensorFlow version 2.2.0.\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After understanding the effects of all the improvement and optimization techniques on the CNN model performance, **the final CNN model can now be defined and trained**:\n",
    "1. with **grayscale images** instead of RGB coloured images.\n",
    "2. for **60 epochs**.\n",
    "3. for **re-distributed classes of age-ranges**.\n",
    "4. with an **optimized architecture**, comprising of:\n",
    "- an input *Conv2D* layer (with 32 filters) paired with an *AveragePooling2D* layer,\n",
    "- 3 pairs of *Conv2D* (with 64, 128 & 256 filters) and *AveragePooling2D* layers,\n",
    "- a *GlobalAveragePooling2D* layer,\n",
    "- 1 *Dense* layer with 132 nodes, and\n",
    "- an output *Dense* layer with 7 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the training dataset and testing dataset to create tensors of images using the filename paths.\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(\"data/images_filenames_labels_train.csv\")\n",
    "test_df = pd.read_csv(\"data/images_filenames_labels_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>content/combined_faces/18_369.jpg</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>content/combined_faces/5_42.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>content/combined_faces/5_204.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>content/combined_faces/39_24.jpg</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>content/combined_faces/22_41.jpg</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            filename  age\n",
       "0  content/combined_faces/18_369.jpg   18\n",
       "1    content/combined_faces/5_42.jpg    5\n",
       "2   content/combined_faces/5_204.jpg    5\n",
       "3   content/combined_faces/39_24.jpg   39\n",
       "4   content/combined_faces/22_41.jpg   22"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping the age column since classes of age-ranges have been re-distributed from 11 to 7 classes.\n",
    "\n",
    "train_df.drop(columns=['target'], inplace=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>content/combined_faces/8_163.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>content/combined_faces/38_66.jpg</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>content/combined_faces/40_177.jpg</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>content/combined_faces/36_267.jpg</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>content/combined_faces/8_349.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            filename  age\n",
       "0   content/combined_faces/8_163.jpg    8\n",
       "1   content/combined_faces/38_66.jpg   38\n",
       "2  content/combined_faces/40_177.jpg   40\n",
       "3  content/combined_faces/36_267.jpg   36\n",
       "4   content/combined_faces/8_349.jpg    8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping the age column since classes of age-ranges have been re-distributed from 11 to 7 classes.\n",
    "\n",
    "test_df.drop(columns=['target'], inplace=True)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to return the class labels corresponding to the re-distributed 7 age-ranges.\n",
    "\n",
    "def class_labels_reassign(age):\n",
    "\n",
    "    if 1 <= age <= 2:\n",
    "        return 0\n",
    "    elif 3 <= age <= 9:\n",
    "        return 1\n",
    "    elif 10 <= age <= 20:\n",
    "        return 2\n",
    "    elif 21 <= age <= 27:\n",
    "        return 3\n",
    "    elif 28 <= age <= 45:\n",
    "        return 4\n",
    "    elif 46 <= age <= 65:\n",
    "        return 5\n",
    "    else:\n",
    "        return 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['target'] = train_df['age'].map(class_labels_reassign)\n",
    "test_df['target'] = test_df['age'].map(class_labels_reassign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    0.279394\n",
       "3    0.199829\n",
       "5    0.167193\n",
       "0    0.095307\n",
       "2    0.093643\n",
       "1    0.084087\n",
       "6    0.080546\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    0.279415\n",
       "3    0.199781\n",
       "5    0.167131\n",
       "0    0.095361\n",
       "2    0.093669\n",
       "1    0.084113\n",
       "6    0.080530\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the filenames and target class labels into lists for augmented train and test datasets.\n",
    "\n",
    "train_filenames_list = list(train_df['filename'])\n",
    "train_labels_list = list(train_df['target'])\n",
    "\n",
    "test_filenames_list = list(test_df['filename'])\n",
    "test_labels_list = list(test_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating tensorflow constants of filenames and labels for augmented train and test datasets from the lists defined above.\n",
    "\n",
    "train_filenames_tensor = tf.constant(train_filenames_list)\n",
    "train_labels_tensor = tf.constant(train_labels_list)\n",
    "\n",
    "test_filenames_tensor = tf.constant(test_filenames_list)\n",
    "test_labels_tensor = tf.constant(test_labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to read the image, decode the image from given tensor and one-hot encode the image label class.\n",
    "# Changing the channels para in tf.io.decode_jpeg from 3 to 1 changes the output images from RGB coloured to grayscale.\n",
    "\n",
    "num_classes = 7\n",
    "\n",
    "def _parse_function(filename, label):\n",
    "    \n",
    "    image_string = tf.io.read_file(filename)\n",
    "    image_decoded = tf.io.decode_jpeg(image_string, channels=1)    # channels=1 to convert to grayscale, channels=3 to convert to RGB.\n",
    "    # image_resized = tf.image.resize(image_decoded, [200, 200])\n",
    "    label = tf.one_hot(label, num_classes)\n",
    "\n",
    "    return image_decoded, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the dataset ready for the neural network.\n",
    "# Using the tensor vectors defined above, accessing the images in the dataset and passing them through the function defined above.\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_filenames_tensor, train_labels_tensor))\n",
    "train_dataset = train_dataset.map(_parse_function)\n",
    "# train_aug_dataset = train_aug_dataset.repeat(3)\n",
    "train_dataset = train_dataset.batch(512)    # Same as batch_size hyperparameter in model.fit() below.\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_filenames_tensor, test_labels_tensor))\n",
    "test_dataset = test_dataset.map(_parse_function)\n",
    "# test_dataset = test_dataset.repeat(3)\n",
    "test_dataset = test_dataset.batch(512)    # Same as batch_size hyperparameter in model.fit() below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 198, 198, 32)      320       \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 99, 99, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 97, 97, 64)        18496     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 46, 46, 128)       73856     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 21, 21, 256)       295168    \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 132)               33924     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 931       \n",
      "=================================================================\n",
      "Total params: 422,695\n",
      "Trainable params: 422,695\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Defining the architecture of the sequential neural network.\n",
    "\n",
    "final_cnn = Sequential()\n",
    "\n",
    "# Input layer with 32 filters, followed by an AveragePooling2D layer.\n",
    "final_cnn.add(Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=(200, 200, 1)))    # 3rd dim = 1 for grayscale images.\n",
    "final_cnn.add(AveragePooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Three Conv2D layers with filters increasing by a factor of 2 for every successive Conv2D layer.\n",
    "final_cnn.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "final_cnn.add(AveragePooling2D(pool_size=(2,2)))\n",
    "\n",
    "final_cnn.add(Conv2D(filters=128, kernel_size=3, activation='relu'))\n",
    "final_cnn.add(AveragePooling2D(pool_size=(2,2)))\n",
    "\n",
    "final_cnn.add(Conv2D(filters=256, kernel_size=3, activation='relu'))\n",
    "final_cnn.add(AveragePooling2D(pool_size=(2,2)))\n",
    "\n",
    "# A GlobalAveragePooling2D layer before going into Dense layers below.\n",
    "# GlobalAveragePooling2D layer gives no. of outputs equal to no. of filters in last Conv2D layer above (256).\n",
    "final_cnn.add(GlobalAveragePooling2D())\n",
    "\n",
    "# One Dense layer with 132 nodes so as to taper down the no. of nodes from no. of outputs of GlobalAveragePooling2D layer above towards no. of nodes in output layer below (7).\n",
    "final_cnn.add(Dense(132, activation='relu'))\n",
    "\n",
    "# Output layer with 7 nodes (equal to the no. of classes).\n",
    "final_cnn.add(Dense(7, activation='softmax'))\n",
    "\n",
    "final_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the above created CNN architecture.\n",
    "\n",
    "final_cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 660s 14s/step - loss: 2.3570 - accuracy: 0.2608 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Fitting the above created CNN model.\n",
    "\n",
    "final_cnn_history = final_cnn.fit(train_dataset,\n",
    "                                  validation_data=test_dataset,\n",
    "                                  epochs=1,\n",
    "                                  shuffle=False    # shuffle=False to reduce randomness and increase reproducibility\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: improve base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following improvements \n",
    "    1. Number of epochs\n",
    "    2. Model archetecture \n",
    "    3. Overfitting \n",
    "    4. Topics not covered in this course (Transfer Learning and Data Augmentation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
